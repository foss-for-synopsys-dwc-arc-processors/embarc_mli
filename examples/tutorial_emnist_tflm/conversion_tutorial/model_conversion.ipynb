{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Converting TensorFlow Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Overview"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "MLI Library from version 1.1 introduces a new way of model deployment for target applications. MLI support has been integrated into Tensorflow Lite Micro framework which means that its tools are now available to MLI users as well. So, alternatively to manual graph mapping you can use TFLM converting capabilities to convert model to MLI compatible format. Also, from MLI Library version 2.0, some kernels uses new layout for weights and [Model Adaptation Tool](https://github.com/foss-for-synopsys-dwc-arc-processors/tflite-micro/tree/main/tensorflow/lite/micro/tools/make/targets/arc#model-adaptation-tool-experimental-feature) is used to convert TFLM models to this new layout.\r\n",
    "\r\n",
    "In this tutorial we'll cover Tensorflow model conversion specific for ARC target application. It implies that all model values (weights and activations) and preferably inputs and outputs should be converted to 8-bit integers.\r\n",
    "\r\n",
    "Since full integer quantization (the one that includes inputs and outputs) is supported in Tensorflow 2 staring from version 2.3 it is important that your setup provides this version or newer. Please, make sure that this and other requirements from *requirements.txt* are satisfied and let's begin!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import tensorflow.compat.v2 as tf\r\n",
    "from tensorflow import keras\r\n",
    "    \r\n",
    "print(tf.__version__)\r\n",
    "assert tf.__version__ >= '2.3'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Definition"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We are going to use a letter recognition model that was trained on EMNIST Letters dataset. Training of this model is described in details in [MLI 1.1 tutorial emnist tensorflow](https://github.com/foss-for-synopsys-dwc-arc-processors/embarc_mli/blob/Release_1.1/examples/tutorial_emnist_tensorflow/example.ipynb) which covers manual mapping. In this tutorial we're just going to define model and load pretrained weights(*mli_cnn_bn.h5*)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense\r\n",
    "from tensorflow.keras.layers import Activation, BatchNormalization, Flatten\r\n",
    "from tensorflow.keras.models import Sequential\r\n",
    "\r\n",
    "img_rows = 28\r\n",
    "img_cols = 28\r\n",
    "num_classes = 26\r\n",
    "input_shape = (img_rows, img_cols, 1)\r\n",
    "filter_x = 5\r\n",
    "filter_y = 5\r\n",
    "\r\n",
    "model = Sequential()\r\n",
    "\r\n",
    "#Conv1\r\n",
    "model.add(Conv2D(filters=16, \r\n",
    "                 kernel_size=(filter_x, filter_y), \r\n",
    "                 padding=\"same\",  \r\n",
    "                 input_shape=input_shape))\r\n",
    "model.add(BatchNormalization())\r\n",
    "model.add(Activation(\"relu\"))\r\n",
    "model.add(MaxPooling2D())\r\n",
    "\r\n",
    "#Conv2\r\n",
    "model.add(Conv2D(filters=32, \r\n",
    "                 kernel_size=(filter_x, filter_y), \r\n",
    "                 padding=\"same\", \r\n",
    "                 input_shape=input_shape))\r\n",
    "model.add(BatchNormalization())\r\n",
    "model.add(Activation(\"relu\"))\r\n",
    "model.add(MaxPooling2D())\r\n",
    "\r\n",
    "#Conv3\r\n",
    "model.add(Conv2D(filters=32, \r\n",
    "                 kernel_size=(filter_x, filter_y), \r\n",
    "                 padding=\"same\", \r\n",
    "                 input_shape=input_shape))\r\n",
    "model.add(BatchNormalization())\r\n",
    "model.add(Activation(\"relu\"))\r\n",
    "model.add(MaxPooling2D())\r\n",
    "\r\n",
    "#FC1\r\n",
    "model.add(Flatten())\r\n",
    "model.add(Dense(64))\r\n",
    "model.add(BatchNormalization())\r\n",
    "model.add(Activation(\"relu\"))\r\n",
    "\r\n",
    "#FC2\r\n",
    "model.add(Dense(num_classes))\r\n",
    "model.add(Activation(\"softmax\"))\r\n",
    "\r\n",
    "model.compile(optimizer='adam',\r\n",
    "              loss='categorical_crossentropy',\r\n",
    "              metrics=['accuracy'])\r\n",
    "\r\n",
    "model.load_weights('mli_cnn_bn.h5')\r\n",
    "\r\n",
    "print(model.summary())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load and Preprocess Images"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Even though we're using pretrained model we still need images from EMNIST dataset for following conversion purposes:\r\n",
    "1. TFLiteConverter requires a representative dataset of input pictures to perform integer quantization\r\n",
    "2. Pictures will be used for converted model testing and evaluation\r\n",
    "\r\n",
    "Load letters test samples from EMNIST dataset:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from emnist import extract_test_samples\r\n",
    "\r\n",
    "test_images, test_labels = extract_test_samples('letters')\r\n",
    "\r\n",
    "# Make class numbering start at 0\r\n",
    "test_labels = test_labels - 1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Preprocessing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Model expects preprocessed images as inputs, so dataset images should undergo following preprocessing steps: \n",
    "1. Reshape (28,28) bitmaps as (28,28,1)\n",
    "2. Perform thinning: set values to either 0 or 255\n",
    "3. Normalize values, so the range becomes [-1.0, 1.0]"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "preprocessed_test_images = test_images.reshape([test_images.shape[0], img_rows, img_cols, 1])\r\n",
    "\r\n",
    "def thinning(image):\r\n",
    "    tmp = np.where(image < 210.0, 0, image)\r\n",
    "    return np.where(tmp > 210.0, 255, tmp)\r\n",
    "\r\n",
    "preprocessed_test_images = thinning(preprocessed_test_images)\r\n",
    "\r\n",
    "preprocessed_test_images = (preprocessed_test_images - 128.0) / 128.0"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Convert Model into TFLite Format"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now that we have the model and EMNIST samples we can convert model using [TFLiteConverter](https://www.tensorflow.org/lite/convert/python_api). \r\n",
    "\r\n",
    "Setup TFLiteConverter to load the model and perform full integer quantization:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\r\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\r\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\r\n",
    "converter.inference_input_type = tf.int8\r\n",
    "converter.inference_output_type = tf.int8"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Provide a representative dataset:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "preprocessed_test_images = tf.cast(preprocessed_test_images, tf.float32)\r\n",
    "emnist_ds = tf.data.Dataset.from_tensor_slices((preprocessed_test_images)).batch(1)\r\n",
    "\r\n",
    "def representative_data_gen():\r\n",
    "    for input_value in emnist_ds.take(100):\r\n",
    "        yield [input_value]\r\n",
    "    \r\n",
    "converter.representative_dataset = representative_data_gen"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Convert the model to TensorFlow Lite format and save it to a file:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pathlib\r\n",
    "\r\n",
    "converted_model = converter.convert()\r\n",
    "\r\n",
    "generated_dir = pathlib.Path(\"generated/\")\r\n",
    "generated_dir.mkdir(exist_ok=True, parents=True)\r\n",
    "converted_model_file = generated_dir/\"emnist_model_int8.tflite\"\r\n",
    "converted_model_file.write_bytes(converted_model)"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluate Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "To ensure that conversion went well let's run the model on a test dataset and check that accuracy is around 90%."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=str(converted_model_file))\r\n",
    "interpreter.allocate_tensors()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Full test set contains 20800 samples. Evaluating int8 model on it might take notable time. For this reason we are going to evaluate model using only 2080 samples, which is 10% of the total. If you want to get more precise estimation, please, extend the number of samples to be evaluated by increasing **max_samples** value."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "max_samples = 2080"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# A helper function to evaluate the TF Lite model using \"test\" dataset.\r\n",
    "def evaluate_model(interpreter):\r\n",
    "    input_index = interpreter.get_input_details()[0][\"index\"]\r\n",
    "    output_index = interpreter.get_output_details()[0][\"index\"]\r\n",
    "    scale, zero_point = interpreter.get_input_details()[0]['quantization']\r\n",
    "\r\n",
    "    prediction_values = []\r\n",
    "    \r\n",
    "    for test_image in preprocessed_test_images[:max_samples]:\r\n",
    "        # Pre-processing: add batch dimension, quantize and convert inputs to int8 to match with\r\n",
    "        # the model's input data format.\r\n",
    "        test_image = np.expand_dims(test_image, axis=0) #.astype(np.float32)\r\n",
    "        test_image = np.int8(test_image / scale + zero_point)\r\n",
    "        interpreter.set_tensor(input_index, test_image)\r\n",
    "\r\n",
    "        interpreter.invoke()\r\n",
    "\r\n",
    "        # Find the letter with highest probability\r\n",
    "        output = interpreter.tensor(output_index)\r\n",
    "        result = np.argmax(output()[0])\r\n",
    "        prediction_values.append(result)\r\n",
    "    \r\n",
    "    accurate_count = 0\r\n",
    "    for index in range(len(prediction_values)):\r\n",
    "        if prediction_values[index] == test_labels[index]:\r\n",
    "            accurate_count += 1\r\n",
    "    accuracy = accurate_count * 1.0 / len(prediction_values)\r\n",
    "\r\n",
    "    return accuracy * 100"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Please, keep in mind that test dataset evaluation on int8 model may take several minutes. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(str(evaluate_model(interpreter)) + \"%\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create a Test Set for Target Application"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In order to test model in a target application we're going to generate a C file containing test samples gathered from EMNIST database. \n",
    "In our case samples are going to be randomly selected:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import random\r\n",
    "\r\n",
    "num_of_samples = 25\r\n",
    "random_test_images = random.sample(range(1, test_images.shape[0]), num_of_samples)\r\n",
    "\r\n",
    "fig=plt.figure(figsize=(5, 5))\r\n",
    "cols = 5\r\n",
    "rows = 5\r\n",
    "\r\n",
    "for plt_idx, img_idx in enumerate(random_test_images, 1):\r\n",
    "    img = test_images[img_idx]\r\n",
    "    fig.add_subplot(rows, cols, plt_idx)\r\n",
    "    plt.imshow(img)\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Write samples to *test_samples.cc* file:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "samples_file = open(\"generated/test_samples.cc\", \"w\")\r\n",
    "\r\n",
    "samples_file.write(\"#include \\\"test_samples.h\\\"\\n\\n\")\r\n",
    "samples_file.write(\"const int kNumSamples = \" + str(num_of_samples) + \";\\n\\n\")\r\n",
    "\r\n",
    "samples = \"\" \r\n",
    "samples_array = \"const TestSample test_samples[kNumSamples] = {\"\r\n",
    "\r\n",
    "for sample_idx, img_idx in enumerate(random_test_images, 1):\r\n",
    "    img_arr = list(np.ndarray.flatten(test_images[img_idx]))\r\n",
    "    var_name = \"sample\" + str(sample_idx)\r\n",
    "    samples += \"TestSample \" + var_name + \" = {\\n\" #+ \"[IMAGE_SIZE] = { \"\r\n",
    "    samples += \"\\t.label = \" + str(test_labels[img_idx]) + \",\\n\" \r\n",
    "    samples += \"\\t.image = {\\n\"\r\n",
    "    wrapped_arr = [img_arr[i:i + 20] for i in range(0, len(img_arr), 20)]\r\n",
    "    for sub_arr in wrapped_arr:\r\n",
    "        samples += \"\\t\\t\" + str(sub_arr)\r\n",
    "    samples += \"\\t}\\n};\\n\\n\"    \r\n",
    "    samples_array += var_name + \", \"\r\n",
    "    \r\n",
    "samples = samples.replace(\"[\", \"\")\r\n",
    "samples = samples.replace(\"]\", \",\\n\")\r\n",
    "samples_array += \"};\\n\"\r\n",
    "\r\n",
    "samples_file.write(samples);\r\n",
    "samples_file.write(samples_array);\r\n",
    "samples_file.close()"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prepare Model for Target Application"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In order to integrate converted model into application that uses tflite-micro with MLI backend we have to convert it to MLI 2.0 layout and then save it as a C array.\r\n",
    "\r\n",
    "For MLI 2.0, it is necessary to use the [Model Adaptation Tool](https://github.com/foss-for-synopsys-dwc-arc-processors/tflite-micro/tree/main/tensorflow/lite/micro/tools/make/targets/arc#model-adaptation-tool-experimental-feature) to convert `emnist_model_int8.tflite`. Invoke it as follows using correct file paths:\r\n",
    "\r\n",
    "```\r\n",
    "python3 adaptation_tool.py <embarc_mli_directory>/examples/tutorial_emnist_tflm/conversion_tutorial/generated/emnist_model_int8.tflite\r\n",
    "```\r\n",
    "\r\n",
    "Save converted model as a C array. One way to do that is to use xxd utility available on Linux. For Windows you can consider tools like MinGW (Git Bash), WSL or Cygwin. Open terminal and run the following command:\r\n",
    "\r\n",
    "```\r\n",
    "cd generated/\r\n",
    "xxd -i emnist_model_int8.tflite > model.h\r\n",
    "```\r\n",
    "\r\n",
    "The model is ready to be integrated into tflite-micro application with MLI 2.0 backend.\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Done"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "You have converted a Tensorflow model into TF Lite format and generated a test set for the application. As a result you should see the following files:\r\n",
    "* */examples/tutorial_emnist_tflm/conversion_tutorial/generated/model.h* - Generated model protobuf.\r\n",
    "*  */examples/tutorial_emnist_tflm/conversion_tutorial/generated/test_samples.cc* - Set of application test samples.\r\n",
    "\r\n",
    "Now you can return to the [Readme file](https://github.com/foss-for-synopsys-dwc-arc-processors/embarc_mli/tree/mli_dev/examples/tutorial_emnist_tflm/conversion_tutorial#using-converted-model-in-application) to know how these artifacts might be used in the example application.\r\n"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}